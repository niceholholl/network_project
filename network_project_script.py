import networkx as nx
import numpy as np
import matplotlib.pyplot as plt

# ---------- í”„ë¡œì íŠ¸ íŒ¨í‚¤ì§€ì— í•„ìš”í•œ ëª¨ë“ˆ ê°€ì ¸ì˜¤ê¸° ----------

# ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜
from network_tool_pkg.utils.preprocessing import preprocess_network
from network_tool_pkg.utils.degree_utils import create_degree_sequence, preprocess_stub
from network_tool_pkg.utils.average_utils import ensemble_average
from network_tool_pkg.utils.global_utils import calculate_global
from network_tool_pkg.utils.plot_utils import plot_degree_hist, average_hist

# ì¤‘ì‹¬ì„± ë° ëœë¤ ëª¨ë¸ ìƒì„± í´ë˜ìŠ¤
from network_tool_pkg.analysis.centrality_generator import CentralityCalculator
from network_tool_pkg.analysis.random_nets_generator import RandomNetGenerator

# ë°ì´í„° ë¡œë” (ì‚¬ìš© ì‹œ ì£¼ì„ í•´ì œ)
# from data_loader_script import load_network_from_file

# ====================================================================
# 1. ë°ì´í„° ì¤€ë¹„
# ====================================================================

# ğŸš¨ íŒŒì¼ ë¡œë“œ ê²½ë¡œ (Google Drive ê²½ë¡œì˜ Collab í™˜ê²½ ê°€ì •, ì‚¬ìš© ì‹œ ì£¼ì„ í•´ì œ)
# FILE_PATH = '/content/drive/MyDrive/data/friendship/6'

# ğŸš¨ ì›ë³¸ ë„¤íŠ¸ì›Œí¬ ë¡œë“œ (load_network_from_file í•¨ìˆ˜ë¥¼ í†µí•´ dataë¥¼ network í˜•íƒœë¡œ ë³€ê²½ ~ data_loader_script.py ì°¸ì¡°)
# G_original = load_network_from_file(FILE_PATH)

# í…ŒìŠ¤íŠ¸ ë° ì˜ˆì‹œë¥¼ ìœ„í•´ karate club networkì˜ ë°ì´í„°ë¥¼ G_originalì— í• ë‹¹ (ë¯¸ì‚¬ìš© ì‹œ ì£¼ì„ ì„¤ì •)
G_original = nx.karate_club_graph()

# ---------- ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤í–‰ ----------

# ë„¤íŠ¸ì›Œí¬ ì „ì²˜ë¦¬
G_project = preprocess_network(G_original)

# degree sequence ì „ì²˜ë¦¬
degrees = create_degree_sequence(G_project)

# degree sequence ë³´ì • (stub í•© ì§ìˆ˜ ë³´ì •)
degrees_project = preprocess_stub(degrees)

print('----- 1ë‹¨ê³„ : ë°ì´í„° ì „ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ -----')

# ====================================================================
# 2. ì œë„ˆë ˆì´í„° ì„¤ì •
# ====================================================================

N = G_project.number_of_nodes()
NUM_SIMULATIONS = 100 
ER_P = 0.08
# BA_M = 2 ~ BA ëª¨ë¸ ë¯¸ì‚¬ìš©

# ---------- í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤í™” ----------

# ì œë„ˆë ˆì´í„° í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤í™”
generator = RandomNetGenerator(N_nodes = N, initial_degrees = degrees_project)

# ì¤‘ì‹¬ì„± ê³„ì‚° í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤í™”
original_calc = CentralityCalculator(G_project)

print('----- 2ë‹¨ê³„ : ëœë¤ ëª¨ë¸ ìƒì„±ê¸°ì˜ ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ -----')

# ====================================================================
# 3. ì›ë³¸ ë¶„í¬ ê³„ì‚° ë° ë¬´ì‘ìœ„ ì•™ìƒë¸” ìƒì„±
# ====================================================================

# ---------- ì›ë³¸ ë„¤íŠ¸ì›Œí¬ì˜ Centrality ê³„ì‚° ----------

# ğŸš¨ í•´ë‹¹ ë¶„ì„ì—ì„œëŠ” Betweenness Centralityì™€ Closeness Centrality ë‘ ê°œë¥¼ ì´ìš©í•˜ì—¬ ë¹„êµ
original_btw = original_calc.calculate_betweenness_centrality()
original_cls = original_calc.calculate_closeness_centrality()

# ---------- ì•™ìƒë¸” ì‹œë®¬ë ˆì´ì…˜ ì´ˆê¸°í™” ----------

# ğŸš¨ í•´ë‹¹ ë¶„ì„ì—ì„œëŠ” BA ëª¨ë¸ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ì„¸ ê°œë§Œì„ ë¹„êµ
# Betweenness Centrality ì €ì¥ ë¦¬ìŠ¤íŠ¸
er_btw_list = []
cf_btw_list = []
cl_btw_list = []

# Closeness Centrality ì €ì¥ ë¦¬ìŠ¤íŠ¸
er_cls_list = []
cf_cls_list = []
cl_cls_list = []

# ë„¤íŠ¸ì›Œí¬ íŠ¹ì§• ë¹„êµë¥¼ ìœ„í•œ ì „ì—­ ì§€í‘œ ì €ì¥ ë¦¬ìŠ¤íŠ¸
er_global_list = []
cf_global_list = []
cl_global_list = []

# ë„¤íŠ¸ì›Œí¬ ì‹œê°í™”ë¥¼ ìœ„í•œ degree ì €ì¥ ë¦¬ìŠ¤íŠ¸
er_degree_list = []
cf_degree_list = []
cl_degree_list = []

# ---------- ì•™ìƒë¸” ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘ ----------

print('----- {}íšŒ ì•™ìƒë¸” ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘ -----'.format(NUM_SIMULATIONS))

for i in range(NUM_SIMULATIONS) :

  # ëª¨ë¸ ìƒì„±
  G_er = generator.create_er_net(ER_P)
  G_cf = generator.create_configuration_net()
  G_cl = generator.create_chunglu_net()

  # ê° ëª¨ë¸ì˜ ê³„ì‚°ê¸° ì¸ìŠ¤í„´ìŠ¤
  calc_er = CentralityCalculator(G_er)
  calc_cf = CentralityCalculator(G_cf)
  calc_cl = CentralityCalculator(G_cl)

  # Betweenness Centrality ê³„ì‚° ë° ì €ì¥
  er_btw_list.append(calc_er.calculate_betweenness_centrality())
  cf_btw_list.append(calc_cf.calculate_betweenness_centrality())
  cl_btw_list.append(calc_cl.calculate_betweenness_centrality())

  # Closeness Centrality ê³„ì‚° ë° ì €ì¥
  er_cls_list.append(calc_er.calculate_closeness_centrality())
  cf_cls_list.append(calc_cf.calculate_closeness_centrality())
  cl_cls_list.append(calc_cl.calculate_closeness_centrality())

  # degree ì €ì¥
  er_degree_list.append([d for _, d in G_er.degree()])
  cf_degree_list.append([d for _, d in G_cf.degree()])
  cl_degree_list.append([d for _, d in G_cl.degree()])

  # ì „ì—­ ì§€í‘œ ê³„ì‚° ë° ì €ì¥
  # ğŸš¨ ì˜ˆì™¸ ì²˜ë¦¬ë¡œ disconnected ì²´í¬ ë° í•´ë‹¹ ì¸ë±ìŠ¤ ì¶œë ¥
  # ğŸš¨ ëœë¤ ëª¨ë¸ ì¼ë¶€ ë„¤íŠ¸ì›Œí¬ê°€ disconnected ë˜ë©´ ì¼ë¶€ ì „ì—­ ì§€í‘œ(APL, DIAM) ê³„ì‚° ë¶ˆê°€
  # ğŸš¨ ì´ ê°’ë“¤ì„ Noneìœ¼ë¡œ ì±„ìš°ê³ , ì§€í‘œì˜ í‰ê·  ë° ë¶„í¬ ê³„ì‚°ì‹œ ê²°ê³¼ê°€ í”ë“¤ë¦´ ìˆ˜ ìˆìŒ
  
  try :
    er_global_list.append(calculate_global(G_er))
  except ValueError :
    print('[ê²½ê³ ] {}/{}ë²ˆì§¸ ER ê·¸ë˜í”„ê°€ diconnected ì…ë‹ˆë‹¤. í‰ê·  ê²½ë¡œ ê¸¸ì´ì™€ ì§€ë¦„ì€ Noneìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.'.format(i, NUM_SIMULATIONS))
    er_global_list.append({'CC': nx.average_clustering(G_er), 'APL': None, 'DIAM': None})

  try :
    cf_global_list.append(calculate_global(G_cf))
  except ValueError :
    print('[ê²½ê³ ] {}/{}ë²ˆì§¸ Configuration ê·¸ë˜í”„ê°€ diconnected ì…ë‹ˆë‹¤. í‰ê·  ê²½ë¡œ ê¸¸ì´ì™€ ì§€ë¦„ì€ Noneìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.'.format(i, NUM_SIMULATIONS))
    cf_global_list.append({'CC': nx.average_clustering(G_cf), 'APL': None, 'DIAM': None})

  try :
    cl_global_list.append(calculate_global(G_cl))
  except ValueError :
    print('[ê²½ê³ ] {}/{}ë²ˆì§¸ Chung-Lu ê·¸ë˜í”„ê°€ diconnected ì…ë‹ˆë‹¤. í‰ê·  ê²½ë¡œ ê¸¸ì´ì™€ ì§€ë¦„ì€ Noneìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.'.format(i, NUM_SIMULATIONS))
    cl_global_list.append({'CC': nx.average_clustering(G_cl), 'APL': None, 'DIAM': None})

print('----- {}íšŒ ì•™ìƒë¸” ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ -----'.format(NUM_SIMULATIONS))
print('----- 3ë‹¨ê³„ : ì›ë³¸ ë¶„í¬ ê³„ì‚° ë° ë¬´ì‘ìœ„ ì•™ìƒë¸” ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ -----')

# ====================================================================
# 4. ì¤‘ì‹¬ì„± ì§€í‘œ ê³„ì‚° (í‰ê· í™” ì‘ì—…)
# ====================================================================

nodes_sorted = sorted(G_project.nodes())

# Betweenness Centrality í‰ê· í™”
original_btw_sorted = np.array([original_btw[n] for n in nodes_sorted])
avg_er_btw = ensemble_average(er_btw_list)
avg_cf_btw = ensemble_average(cf_btw_list)
avg_cl_btw = ensemble_average(cl_btw_list)

# Closeness Centrality í‰ê· í™”
original_cls_sorted = np.array([original_cls[n] for n in nodes_sorted])
avg_er_cls = ensemble_average(er_cls_list)
avg_cf_cls = ensemble_average(cf_cls_list)
avg_cl_cls = ensemble_average(cl_cls_list)

print('----- 4ë‹¨ê³„ : ì¤‘ì‹¬ì„± ì§€í‘œ ë¹„êµë¥¼ ìœ„í•œ ì•™ìƒë¸” í‰ê· í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ -----')

# ====================================================================
# 5. ì „ì—­ ì§€í‘œ ê³„ì‚°
# ====================================================================

# ì›ë³¸ ë„¤íŠ¸ì›Œí¬ì˜ ì „ì—­ ì§€í‘œ ê³„ì‚°
original_global_metrics = calculate_global(G_project)

# ëœë¤ ëª¨ë¸ ë„¤íŠ¸ì›Œí¬ì˜ ì „ì—­ ì§€í‘œ ê³„ì‚°
er_global_metrics = ensemble_average(er_global_list)
cf_global_metrics = ensemble_average(cf_global_list)
cl_global_metrics = ensemble_average(cl_global_list)

print('----- 5ë‹¨ê³„ : ì „ì—­ ì§€í‘œ ë¹„êµë¥¼ ìœ„í•œ ê³„ì‚°ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ -----')

# ====================================================================
# 6. ì‹œê°í™”
# ====================================================================

# ---------- ì›ë³¸ ë„¤íŠ¸ì›Œí¬ vs ëœë¤ ë„¤íŠ¸ì›Œí¬ ëª¨ë¸ Degree ë¹„êµ ë° ì‹œê°í™” ----------

avg_er_hist = average_hist(er_degree_list)
avg_cf_hist = average_hist(cf_degree_list)
avg_cl_hist = average_hist(cl_degree_list)

fig, ax = plt.subplots(1, 3, figsize = (27, 5))

plot_degree_hist(ax[0], degrees_project, avg_er_hist, 'ER')
plot_degree_hist(ax[1], degrees_project, avg_cf_hist, 'Configuration')
plot_degree_hist(ax[2], degrees_project, avg_cl_hist, 'Chung-Lu')

plt.tight_layout()
plt.savefig('Degree_compare.pdf', bbox_inches = 'tight')
plt.close()

print('----- Degree Histogram ì‹œê°í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ -----')

# ---------- Betweennes Centrality ë¹„êµ ë° ì‹œê°í™” ----------

fig, ax = plt.subplots(1, 1, figsize = (9, 5))

ax.plot(nodes_sorted, original_btw_sorted, color = 'grey', label = 'Original')
ax.plot(nodes_sorted, avg_er_btw, linestyle = '--', color = 'blue', label = 'ER')
ax.plot(nodes_sorted, avg_cf_btw, linestyle = '--', color = 'red', label = 'Configuration')
ax.plot(nodes_sorted, avg_cl_btw, linestyle = '--', color = 'green', label = 'Chung-Lu')

ax.set_title('Betweenness Centrality: Original vs Random Models')
ax.set_xlabel('Node ID')
ax.set_ylabel('Betweenness Centrality')
ax.grid(alpha = 0.4)
ax.legend()

plt.tight_layout()
plt.savefig('Betweenness_compare.pdf', bbox_inches = 'tight')
plt.close()

print('----- Betweenness Centrality ì‹œê°í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ -----')

# ---------- Closeness Centrality ë¹„êµ ë° ì‹œê°í™” ----------

fig, ax = plt.subplots(1, 1, figsize = (9, 5))

ax.plot(nodes_sorted, original_cls_sorted, color = 'grey', label = 'Original')
ax.plot(nodes_sorted, avg_er_cls, linestyle = '--', color = 'blue', label = 'ER')
ax.plot(nodes_sorted, avg_cf_cls, linestyle = '--', color = 'red', label = 'Configuration')
ax.plot(nodes_sorted, avg_cl_cls, linestyle = '--', color = 'green', label = 'Chung-Lu')

ax.set_title('Closeness Centrality: Original vs Random Models')
ax.set_xlabel('Node ID')
ax.set_ylabel('Closeness Centrality')
ax.grid(alpha = 0.4)
ax.legend()

plt.tight_layout()
plt.savefig('Closeness_compare.pdf', bbox_inches = 'tight')
plt.close()

print('----- Closeness Centrality ì‹œê°í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ -----')

# ---------- ì „ì—­ ì§€í‘œ ë¹„êµ ë° ì‹œê°í™” ----------

fig, ax = plt.subplots(1, 3, figsize = (9, 5))

metric_names = list(original_global_metrics.keys())

original_vals = [original_global_metrics[m] for m in metric_names]
er_vals = [er_global_metrics[m] for m in metric_names]
cf_vals = [cf_global_metrics[m] for m in metric_names]
cl_vals = [cl_global_metrics[m] for m in metric_names]

models = ['Original', 'ER', 'Config', 'Chung-Lu']
colors = ['black', 'blue', 'red', 'green']
x_single = 0

for i, metric in enumerate(metric_names) :
  x_pos = np.arange(len(models))
  y_vals = [original_vals[i], er_vals[i], cf_vals[i], cl_vals[i]]

  for j, (x,y) in enumerate(zip(x_pos, y_vals)) :
    ax[i].scatter(x, y, color = colors[j], s = 120)
    ax[i].text(x, y, '{:.2f}'.format(y), ha = 'center', va = 'center', fontsize = 6, color = 'white')

  ax[i].set_xticks(x_pos)
  ax[i].set_xticklabels(models, rotation = 20)
  ax[i].set_ylabel('{} value'.format(metric))
  ax[i].set_title('{} Comparison'.format(metric))
  ax[i].grid(alpha = 0.4)

plt.tight_layout()
plt.savefig('Global_compare.pdf', bbox_inches = 'tight')
plt.close()

print('----- ì „ì—­ ì§€í‘œ(í´ëŸ¬ìŠ¤í„°ë§ ê³„ìˆ˜, í‰ê·  ê²½ë¡œ ê¸¸ì´, ì§€ë¦„) ì‹œê°í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ -----')
print('----- 6ë‹¨ê³„ : í•´ë‹¹ í”„ë¡œì íŠ¸ì˜ ìµœì¢… ì‹œê°í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ -----')

    







            







