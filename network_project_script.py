import networkx as nx
import numpy as np
import matplotlib.pyplot as plt

# ---------- í”„ë¡œì íŠ¸ íŒ¨í‚¤ì§€ì— í•„ìš”í•œ ëª¨ë“ˆ ê°€ì ¸ì˜¤ê¸° ----------

# ë°ì´í„° ì „ì²˜ë¦¬ í•¨ìˆ˜
from network_tool_pkg.utils.preprocessing import preprocess_network
from network_tool_pkg.utils.degree_utils import create_degree_sequence, preprocess_stub
from network_tool_pkg.utils.average_utils import ensemble_average
from network_tool_pkg.utils.global_utils import calculate_global, get_largest_connected_component, diagnose_lcc_size
from network_tool_pkg.utils.plot_utils import plot_degree_hist, average_hist

# ì¤‘ì‹¬ì„± ë° ëœë¤ ëª¨ë¸ ìƒì„± í´ë˜ìŠ¤
from network_tool_pkg.analysis.centrality_generator import CentralityCalculator
from network_tool_pkg.analysis.random_nets_generator import RandomNetGenerator

# ë°ì´í„° ë¡œë” (ì‚¬ìš© ì‹œ ì£¼ì„ í•´ì œ)
from data_loader_script import load_network_from_file

# ====================================================================
# 1. ë°ì´í„° ì¤€ë¹„
# ====================================================================

# ğŸš¨ íŒŒì¼ ë¡œë“œ ê²½ë¡œ (Google Drive ê²½ë¡œì˜ Collab í™˜ê²½ ê°€ì •, ì‚¬ìš© ì‹œ ì£¼ì„ í•´ì œ)
# FILE_PATH = '/content/drive/MyDrive/data/friendship/6'
# FILE_PATH = "C:/network_pj/network_project/data/friendship/6"

# ğŸš¨ ì›ë³¸ ë„¤íŠ¸ì›Œí¬ ë¡œë“œ (load_network_from_file í•¨ìˆ˜ë¥¼ í†µí•´ dataë¥¼ network í˜•íƒœë¡œ ë³€ê²½ ~ data_loader_script.py ì°¸ì¡°)
# G_original = load_network_from_file(FILE_PATH)

# í…ŒìŠ¤íŠ¸ ë° ì˜ˆì‹œë¥¼ ìœ„í•´ karate club networkì˜ ë°ì´í„°ë¥¼ G_originalì— í• ë‹¹ (ë¯¸ì‚¬ìš© ì‹œ ì£¼ì„ ì„¤ì •)
G_original = nx.karate_club_graph()

# ---------- ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤í–‰ ----------

# ë„¤íŠ¸ì›Œí¬ ì „ì²˜ë¦¬
G_project = preprocess_network(G_original)

# degree sequence ì „ì²˜ë¦¬
degrees = create_degree_sequence(G_project)

# degree sequence ë³´ì • (stub í•© ì§ìˆ˜ ë³´ì •)
degrees_project = preprocess_stub(degrees)

print('----- 1ë‹¨ê³„ : ë°ì´í„° ì „ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ -----')

# ====================================================================
# 2. ì œë„ˆë ˆì´í„° ì„¤ì •
# ====================================================================

N = G_project.number_of_nodes()
NUM_SIMULATIONS = 100 
ER_P = 0.14
# BA_M = 2 ~ BA ëª¨ë¸ ë¯¸ì‚¬ìš©

# ---------- í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤í™” ----------

# ì œë„ˆë ˆì´í„° í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤í™”
print(f"DEBUG N-CHECK 1: ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸ì˜ ìµœì¢… N ê°’ = {N}") # ğŸ‘ˆ N=34ê°€ ë‚˜ì™€ì•¼ í•¨
generator = RandomNetGenerator(N_nodes = N, initial_degrees = degrees_project)

# ì¤‘ì‹¬ì„± ê³„ì‚° í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤í™”
original_calc = CentralityCalculator(G_project)

print('----- 2ë‹¨ê³„ : ëœë¤ ëª¨ë¸ ìƒì„±ê¸°ì˜ ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ -----')

# ====================================================================
# 3. ì›ë³¸ ë¶„í¬ ê³„ì‚° ë° ë¬´ì‘ìœ„ ì•™ìƒë¸” ìƒì„±
# ====================================================================

# ---------- ì›ë³¸ ë„¤íŠ¸ì›Œí¬ì˜ Centrality ê³„ì‚° ----------

# ğŸš¨ í•´ë‹¹ ë¶„ì„ì—ì„œëŠ” Betweenness Centralityì™€ Closeness Centrality ë‘ ê°œë¥¼ ì´ìš©í•˜ì—¬ ë¹„êµ
original_btw = original_calc.calculate_betweenness_centrality()
original_cls = original_calc.calculate_closeness_centrality()

# ---------- ì•™ìƒë¸” ì‹œë®¬ë ˆì´ì…˜ ì´ˆê¸°í™” ----------

# ğŸš¨ í•´ë‹¹ ë¶„ì„ì—ì„œëŠ” BA ëª¨ë¸ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ì„¸ ê°œë§Œì„ ë¹„êµ
# Betweenness Centrality ì €ì¥ ë¦¬ìŠ¤íŠ¸
er_btw_list = []
cf_btw_list = []
cl_btw_list = []

# Closeness Centrality ì €ì¥ ë¦¬ìŠ¤íŠ¸
er_cls_list = []
cf_cls_list = []
cl_cls_list = []

# ë„¤íŠ¸ì›Œí¬ íŠ¹ì§• ë¹„êµë¥¼ ìœ„í•œ ì „ì—­ ì§€í‘œ ì €ì¥ ë¦¬ìŠ¤íŠ¸
er_global_list = []
cf_global_list = []
cl_global_list = []

# ë„¤íŠ¸ì›Œí¬ ì‹œê°í™”ë¥¼ ìœ„í•œ degree ì €ì¥ ë¦¬ìŠ¤íŠ¸
er_degree_list = []
cf_degree_list = []
cl_degree_list = []

# ---------- ì•™ìƒë¸” ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘ ----------

print('----- {}íšŒ ì•™ìƒë¸” ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘ -----'.format(NUM_SIMULATIONS))

for i in range(NUM_SIMULATIONS) :

  # ëª¨ë¸ ìƒì„±
  print(f"DEBUG P-CHECK: í˜„ì¬ ER_P ê°’ = {ER_P}")
  G_er = generator.create_er_net(ER_P)
  G_cf = generator.create_configuration_net()
  G_cl = generator.create_chunglu_net()

  # ê° ëª¨ë¸ì˜ ê³„ì‚°ê¸° ì¸ìŠ¤í„´ìŠ¤
  calc_er = CentralityCalculator(G_er)
  calc_cf = CentralityCalculator(G_cf)
  calc_cl = CentralityCalculator(G_cl)

  # Betweenness Centrality ê³„ì‚° ë° ì €ì¥
  er_btw_list.append(calc_er.calculate_betweenness_centrality())
  cf_btw_list.append(calc_cf.calculate_betweenness_centrality())
  cl_btw_list.append(calc_cl.calculate_betweenness_centrality())

  # Closeness Centrality ê³„ì‚° ë° ì €ì¥
  # er_cls_list.append(calc_er.calculate_closeness_centrality())
  # cf_cls_list.append(calc_cf.calculate_closeness_centrality())
  # cl_cls_list.append(calc_cl.calculate_closeness_centrality())

  # degree ì €ì¥
  er_degree_list.append([d for _, d in G_er.degree()])
  cf_degree_list.append([d for _, d in G_cf.degree()])
  cl_degree_list.append([d for _, d in G_cl.degree()])
  
  graph_data_list = [
        (G_er, er_global_list, er_cls_list, calc_er, 'ER'), 
        (G_cf, cf_global_list, cf_cls_list, calc_cf, 'Configuration'), 
        (G_cl, cl_global_list, cl_cls_list, calc_cl, 'Chung-Lu')
    ]
  
      # 1. ER ëª¨ë¸ (LCC ë³´ì • ì ìš©)
  try :
      G_er_safe = G_er 
      
      # ğŸŒŸ LCC ë³´ì •: ë‹¨ì ˆ í™•ì¸ í›„ LCC ì¶”ì¶œ
      if not nx.is_connected(G_er):
          G_er_safe = get_largest_connected_component(G_er)
          print('[ê²½ê³ ] {}/{}ë²ˆì§¸ ER ê·¸ë˜í”„ê°€ disconnectedì´ë¯€ë¡œ LCCë¡œ ë³´ì •í•©ë‹ˆë‹¤.'.format(i + 1, NUM_SIMULATIONS))
      

      cls_scores = calc_er.calculate_closeness_centrality() 
      er_cls_list.append(cls_scores) # ìœ íš¨í•œ ì ìˆ˜ë¥¼ ì €ì¥
  
      # ğŸŒŸ ì•ˆì „ í™•ì¸: LCC ì¶”ì¶œ í›„ì—ë„ ë…¸ë“œê°€ 2ê°œ ë¯¸ë§Œì´ë©´ ê³„ì‚° ë¶ˆê°€
      if G_er_safe.number_of_nodes() < 2:
          raise ValueError("LCC ì¶”ì¶œ í›„ ë…¸ë“œ ìˆ˜ê°€ 2ê°œ ë¯¸ë§Œì´ì–´ì„œ APL/DIAM ê³„ì‚° ë¶ˆê°€.")
          
      er_global_list.append(calculate_global(G_er_safe))

  except ValueError : 
      # APL/DIAM ê³„ì‚° ë¶ˆê°€ ì‹œ ì•ˆì „ê°’(0)ìœ¼ë¡œ ëŒ€ì²´ (CCëŠ” ê³„ì‚° ê°€ëŠ¥)
      safe_cc = nx.average_clustering(G_er) 
      print('[ê²½ê³ ] {}/{}ë²ˆì§¸ ER ê·¸ë˜í”„ì˜ APL/DIAM ê³„ì‚° ì‹¤íŒ¨. NaNìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.'.format(i + 1, NUM_SIMULATIONS))
      er_global_list.append({'CC': safe_cc, 'APL': np.nan, 'DIAM': np.nan}) # None ëŒ€ì‹  0ìœ¼ë¡œ ì €ì¥

  # 2. Configuration ëª¨ë¸ (LCC ë³´ì • ì ìš©)
  try :
      G_cf_safe = G_cf
      if not nx.is_connected(G_cf):
          G_cf_safe = get_largest_connected_component(G_cf)
          print('[ê²½ê³ ] {}/{}ë²ˆì§¸ CF ê·¸ë˜í”„ê°€ disconnectedì´ë¯€ë¡œ LCCë¡œ ë³´ì •í•©ë‹ˆë‹¤.'.format(i + 1, NUM_SIMULATIONS))
      
      cls_scores = calc_cf.calculate_closeness_centrality() 
      cf_cls_list.append(cls_scores) # ìœ íš¨í•œ ì ìˆ˜ë¥¼ ì €ì¥

      if G_cf_safe.number_of_nodes() < 2:
          raise ValueError("LCC ì¶”ì¶œ í›„ ë…¸ë“œ ìˆ˜ê°€ 2ê°œ ë¯¸ë§Œì´ì–´ì„œ APL/DIAM ê³„ì‚° ë¶ˆê°€.")
          
      cf_global_list.append(calculate_global(G_cf_safe))

  except ValueError : 
      safe_cc = nx.average_clustering(G_cf)
      print('[ê²½ê³ ] {}/{}ë²ˆì§¸ CF ê·¸ë˜í”„ì˜ APL/DIAM ê³„ì‚° ì‹¤íŒ¨. NaNìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.'.format(i + 1, NUM_SIMULATIONS))
      cf_global_list.append({'CC': safe_cc, 'APL': np.nan, 'DIAM': np.nan}) 


  # 3. Chung-Lu ëª¨ë¸ (LCC ë³´ì • ì ìš©)
  try :
      G_cl_safe = G_cl
      if not nx.is_connected(G_cl):
          G_cl_safe = get_largest_connected_component(G_cl)
          print('[ê²½ê³ ] {}/{}ë²ˆì§¸ CL ê·¸ë˜í”„ê°€ disconnectedì´ë¯€ë¡œ LCCë¡œ ë³´ì •í•©ë‹ˆë‹¤.'.format(i + 1, NUM_SIMULATIONS))
      
      cls_scores = calc_cl.calculate_closeness_centrality() 
      cl_cls_list.append(cls_scores) # ìœ íš¨í•œ ì ìˆ˜ë¥¼ ì €ì¥

      if G_cl_safe.number_of_nodes() < 2:
          raise ValueError("LCC ì¶”ì¶œ í›„ ë…¸ë“œ ìˆ˜ê°€ 2ê°œ ë¯¸ë§Œì´ì–´ì„œ APL/DIAM ê³„ì‚° ë¶ˆê°€.")
          
      cl_global_list.append(calculate_global(G_cl_safe))

  except ValueError : 
      safe_cc = nx.average_clustering(G_cl)
      print('[ê²½ê³ ] {}/{}ë²ˆì§¸ CL ê·¸ë˜í”„ì˜ APL/DIAM ê³„ì‚° ì‹¤íŒ¨. NaNìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.'.format(i + 1, NUM_SIMULATIONS))
      cl_global_list.append({'CC': safe_cc, 'APL': np.nan, 'DIAM': np.nan})

er_avg = ensemble_average(er_global_list)
print(f"DEBUG FINAL-APL: ER ëª¨ë¸ ìµœì¢… APL í‰ê·  = {er_avg[1]}")
print('----- {}íšŒ ì•™ìƒë¸” ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ -----'.format(NUM_SIMULATIONS))
print('----- 3ë‹¨ê³„ : ì›ë³¸ ë¶„í¬ ê³„ì‚° ë° ë¬´ì‘ìœ„ ì•™ìƒë¸” ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ -----')

# ====================================================================
# 4. ì¤‘ì‹¬ì„± ì§€í‘œ ê³„ì‚° (í‰ê· í™” ì‘ì—…)
# ====================================================================

nodes_sorted = sorted(G_project.nodes())

# Betweenness Centrality í‰ê· í™”
original_btw_sorted = np.array([original_btw[n] for n in nodes_sorted])
avg_er_btw = ensemble_average(er_btw_list)
avg_cf_btw = ensemble_average(cf_btw_list)
avg_cl_btw = ensemble_average(cl_btw_list)

# Closeness Centrality í‰ê· í™”
original_cls_sorted = np.array([original_cls[n] for n in nodes_sorted])
avg_er_cls = ensemble_average(er_cls_list)
avg_cf_cls = ensemble_average(cf_cls_list)
avg_cl_cls = ensemble_average(cl_cls_list)

print('----- 4ë‹¨ê³„ : ì¤‘ì‹¬ì„± ì§€í‘œ ë¹„êµë¥¼ ìœ„í•œ ì•™ìƒë¸” í‰ê· í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ -----')

# ====================================================================
# 5. ì „ì—­ ì§€í‘œ ê³„ì‚°
# ====================================================================

# ì›ë³¸ ë„¤íŠ¸ì›Œí¬ì˜ ì „ì—­ ì§€í‘œ ê³„ì‚°
original_global_metrics = calculate_global(G_project)

# ëœë¤ ëª¨ë¸ ë„¤íŠ¸ì›Œí¬ì˜ ì „ì—­ ì§€í‘œ ê³„ì‚°
er_global_metrics = ensemble_average(er_global_list)
cf_global_metrics = ensemble_average(cf_global_list)
cl_global_metrics = ensemble_average(cl_global_list)

print('----- 5ë‹¨ê³„ : ì „ì—­ ì§€í‘œ ë¹„êµë¥¼ ìœ„í•œ ê³„ì‚°ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ -----')
diagnose_lcc_size(G_project, generator, ER_P)
# ====================================================================
# 6. ì‹œê°í™”
# ====================================================================

# ---------- ì›ë³¸ ë„¤íŠ¸ì›Œí¬ vs ëœë¤ ë„¤íŠ¸ì›Œí¬ ëª¨ë¸ Degree ë¹„êµ ë° ì‹œê°í™” ----------

k_max_orig = max(degrees_project) if degrees_project else 0 

# 2. ğŸŒŸ average_hist í•¨ìˆ˜ í˜¸ì¶œ ì‹œ k_max_orig ì¸ìë¥¼ ì¶”ê°€
avg_er_hist = average_hist(er_degree_list, k_max_orig) # ğŸŒŸ ìˆ˜ì •
avg_cf_hist = average_hist(cf_degree_list, k_max_orig) # ğŸŒŸ ìˆ˜ì •
avg_cl_hist = average_hist(cl_degree_list, k_max_orig) # ğŸŒŸ ìˆ˜ì •

fig, ax = plt.subplots(1, 3, figsize = (27, 5))

plot_degree_hist(ax[0], degrees_project, avg_er_hist, 'ER')
plot_degree_hist(ax[1], degrees_project, avg_cf_hist, 'Configuration')
plot_degree_hist(ax[2], degrees_project, avg_cl_hist, 'Chung-Lu')

plt.tight_layout()
plt.savefig('Degree_compare.pdf', bbox_inches = 'tight')
plt.close()

print('----- Degree Histogram ì‹œê°í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ -----')

# -----------------------------------------------------------
# Betweenness Centrality ë¹„êµ ë° ì‹œê°í™” (ë¶„í¬ BAR PLOTìœ¼ë¡œ ìˆ˜ì •)

# 1. ëª¨ë“  Betweenness ë°ì´í„°ë¥¼ í•©ì³ ê³µí†µ Bins ì„¤ì •
all_btw_scores = original_btw_sorted + avg_er_btw + avg_cf_btw + avg_cl_btw
bins_edges_btw = np.linspace(min(all_btw_scores), max(all_btw_scores), 30)
# 2. ê° ëª¨ë¸ì˜ í™•ë¥  ë¶„í¬ (P(B)) ê³„ì‚°
P_B_original = np.histogram(original_btw_sorted, bins=bins_edges_btw, density=True)[0]
P_B_er_avg = np.histogram(avg_er_btw, bins=bins_edges_btw, density=True)[0]
P_B_cf_avg = np.histogram(avg_cf_btw, bins=bins_edges_btw, density=True)[0]
P_B_cl_avg = np.histogram(avg_cl_btw, bins=bins_edges_btw, density=True)[0]

# 3. Xì¶• ìœ„ì¹˜ ë° ë„ˆë¹„ ê³„ì‚°
bin_centers_btw = 0.5 * (bins_edges_btw[:-1] + bins_edges_btw[1:])
bar_width = 0.2 * (bin_centers_btw[1] - bin_centers_btw[0]) # 4ê°œ ë§‰ëŒ€ ë‚˜ì—´ì„ ìœ„í•´ ì¡°ì •

fig, ax = plt.subplots(1, 1, figsize = (12, 6))

# 4. ğŸŒŸ BAR PLOTìœ¼ë¡œ ë¶„í¬ ë¹„êµ
ax.bar(bin_centers_btw - bar_width * 1.5, P_B_original, width=bar_width, alpha=0.7, color='grey', label='Original')
ax.bar(bin_centers_btw - bar_width * 0.5, P_B_er_avg, width=bar_width, alpha=0.7, color='blue', label='ER')
ax.bar(bin_centers_btw + bar_width * 0.5, P_B_cf_avg, width=bar_width, alpha=0.7, color='red', label='Configuration')
ax.bar(bin_centers_btw + bar_width * 1.5, P_B_cl_avg, width=bar_width, alpha=0.7, color='green', label='Chung-Lu')

ax.set_title('Betweenness Centrality Distribution Comparison')
ax.set_xlabel('Betweenness Centrality Score')
ax.set_ylabel('Probability Density')
ax.grid(alpha = 0.4)
ax.axvline(x=0, color='grey', linewidth=1.5, linestyle='--')
ax.legend()
plt.tight_layout()
plt.savefig('Betweenness_compare.pdf', bbox_inches = 'tight')
plt.close()

print('----- Betweenness Centrality ì‹œê°í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ -----')

# -----------------------------------------------------------
# Closeness Centrality ë¹„êµ ë° ì‹œê°í™” (ë¶„í¬ BAR PLOTìœ¼ë¡œ ìˆ˜ì •)

# 1. ëª¨ë“  Closeness ë°ì´í„°ë¥¼ í•©ì³ ê³µí†µ Bins ì„¤ì •
# all_cls_scores = original_cls_sorted + avg_er_cls + avg_cf_cls + avg_cl_cls
# bins_edges_cls = np.linspace(min(all_cls_scores), max(all_cls_scores), 30)
# 1. ì•™ìƒë¸” ë¦¬ìŠ¤íŠ¸ í‰íƒ„í™” (ë¦¬ìŠ¤íŠ¸ì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ë‹¨ì¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¦)
er_all_cls = [score for dist in er_cls_list for score in dist.values()]
cf_all_cls = [score for dist in cf_cls_list for score in dist.values()]
cl_all_cls = [score for dist in cl_cls_list for score in dist.values()]

# 2. ì›ë³¸ ê°’ ì¶”ì¶œ (í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ì›ë³¸ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°›ì•˜ìœ¼ë¯€ë¡œ)
# original_clsëŠ” ë”•ì…”ë„ˆë¦¬ì´ë¯€ë¡œ ê°’ë§Œ ì¶”ì¶œ
original_cls_values = list(original_cls.values()) 

# 3. ğŸŒŸ ëª¨ë“  ë°ì´í„°ë¥¼ í•©ì³ ìµœì¢… ë²”ìœ„ ì„¤ì • ë¦¬ìŠ¤íŠ¸ ìƒì„±
all_cls_scores = original_cls_values + er_all_cls + cf_all_cls + cl_all_cls

min_val = np.min(all_cls_scores) 
max_val = np.max(all_cls_scores)

# ì‹¤ì œ ë°ì´í„°ê°€ 0.25ì—ì„œ 0.65 ì‚¬ì´ì— ëª¨ë‘ í¬í•¨ë˜ë„ë¡ ì•ˆì „ ë²”ìœ„ ì„¤ì •
FIXED_MIN = 0.25
FIXED_MAX = 0.60

# ğŸŒŸ min/max ê°’ì´ FIXED_MIN/MAXë¥¼ ë²—ì–´ë‚˜ì§€ ì•Šë„ë¡ ì¡°ì •
min_range = min(min_val, FIXED_MIN)
max_range = max(max_val, FIXED_MAX)

# bins_edges_clsë¥¼ ê³ ì •ëœ ë²”ìœ„ë¡œ ì¬ê³„ì‚°
bins_edges_cls = np.linspace(min_range, max_range, 30)

# 2. ê° ëª¨ë¸ì˜ í™•ë¥  ë¶„í¬ (P(C)) ê³„ì‚°
P_C_original = np.histogram(original_cls_sorted, bins=bins_edges_cls, density=True)[0]
P_C_er_avg = np.histogram(avg_er_cls, bins=bins_edges_cls, density=True)[0]
P_C_cf_avg = np.histogram(avg_cf_cls, bins=bins_edges_cls, density=True)[0]
P_C_cl_avg = np.histogram(avg_cl_cls, bins=bins_edges_cls, density=True)[0]

# 3. Xì¶• ìœ„ì¹˜ ë° ë„ˆë¹„ ê³„ì‚°
bin_centers_cls = 0.5 * (bins_edges_cls[:-1] + bins_edges_cls[1:])
bar_width = 0.2 * (bin_centers_cls[1] - bin_centers_cls[0]) 

fig, ax = plt.subplots(1, 1, figsize = (12, 6))

# 4. ğŸŒŸ BAR PLOTìœ¼ë¡œ ë¶„í¬ ë¹„êµ
ax.bar(bin_centers_cls - bar_width * 1.5, P_C_original, width=bar_width, alpha=0.7, color='grey', label='Original')
ax.bar(bin_centers_cls - bar_width * 0.5, P_C_er_avg, width=bar_width, alpha=0.7, color='blue', label='ER')
ax.bar(bin_centers_cls + bar_width * 0.5, P_C_cf_avg, width=bar_width, alpha=0.7, color='red', label='Configuration')
ax.bar(bin_centers_cls + bar_width * 1.5, P_C_cl_avg, width=bar_width, alpha=0.7, color='green', label='Chung-Lu')

ax.set_xlim(left=0)
ax.set_title('Closeness Centrality Distribution Comparison')
ax.set_xlabel('Closeness Centrality Score')
ax.set_ylabel('Probability Density')
ax.grid(alpha = 0.4)
ax.legend()
ax.axvline(x=0, color='grey', linewidth=1.5, linestyle='--')
plt.tight_layout()
plt.savefig('Closeness_compare.pdf', bbox_inches = 'tight')
plt.close()

print('----- Closeness Centrality ì‹œê°í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ -----')

# ---------- ì „ì—­ ì§€í‘œ ë¹„êµ ë° ì‹œê°í™” ----------

fig, ax = plt.subplots(1, 3, figsize = (9, 5))

metric_names = list(original_global_metrics.keys())

original_vals = [original_global_metrics[m] for m in metric_names]
er_vals = er_global_metrics
cf_vals = cf_global_metrics
cl_vals = cl_global_metrics

models = ['Original', 'ER', 'Config', 'Chung-Lu']
colors = ['black', 'blue', 'red', 'green']
x_single = 0

for i, metric in enumerate(metric_names) :
  x_pos = np.arange(len(models))
  y_vals = [original_vals[i], er_vals[i], cf_vals[i], cl_vals[i]]

  for j, (x,y) in enumerate(zip(x_pos, y_vals)) :
    ax[i].scatter(x, y, color = colors[j], s = 120)
    ax[i].text(x, y, '{:.2f}'.format(y), ha = 'center', va = 'center', fontsize = 6, color = 'white')

  ax[i].set_xticks(x_pos)
  ax[i].set_xticklabels(models, rotation = 20)
  ax[i].set_ylabel('{} value'.format(metric))
  ax[i].set_title('{} Comparison'.format(metric))
  ax[i].grid(alpha = 0.4)

plt.tight_layout()
plt.savefig('Global_compare.pdf', bbox_inches = 'tight')
plt.close()

print('----- ì „ì—­ ì§€í‘œ(í´ëŸ¬ìŠ¤í„°ë§ ê³„ìˆ˜, í‰ê·  ê²½ë¡œ ê¸¸ì´, ì§€ë¦„) ì‹œê°í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ -----')
print('----- 6ë‹¨ê³„ : í•´ë‹¹ í”„ë¡œì íŠ¸ì˜ ìµœì¢… ì‹œê°í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ -----')
